# Links from "Long-Context LLMs vs. RAG: Cost, Speed & Accuracy Research"

- https://openreview.net/forum?id=R6q67CDBCH
- https://arxiv.org/html/2507.11538v1
- https://www.mdpi.com/2079-9292/14/21/4349
- https://www.mdpi.com/2079-9292/13/23/4712
- https://www.getmaxim.ai/articles/prompt-chaining-for-ai-engineers-a-practical-guide-to-improving-llm-output-quality/
- https://orq.ai/blog/prompt-structure-chaining
- https://pmc.ncbi.nlm.nih.gov/articles/PMC12407621/
- https://aclanthology.org/2024.bionlp-1.4.pdf
- https://www.meilisearch.com/blog/rag-vs-long-context-llms
- https://arxiv.org/abs/2407.16833
- https://aclanthology.org/2024.emnlp-industry.66/
- https://www.anthropic.com/news/prompt-caching
- https://ngrok.com/blog/prompt-caching/
- https://mcginniscommawill.com/posts/2025-11-17-llm-prompt-caching-comparison/
- https://www.elastic.co/search-labs/blog/rag-vs-long-context-model-llm
- https://byteiota.com/rag-vs-long-context-2026-retrieval-debate/
- https://runloop.ai/blog/latency-vs-tokenization-the-fundamental-trade-off-shaping-llm-research
- https://docs.anyscale.com/llm/serving/benchmarking/metrics
- https://www.tribe.ai/applied-ai/reducing-latency-and-cost-at-scale-llm-performance
- https://introl.com/blog/prompt-caching-infrastructure-llm-cost-latency-reduction-guide-2025
- https://arxiv.org/abs/2307.03172
- https://cs.stanford.edu/~nfliu/papers/lost-in-the-middle.arxiv2023.pdf
- https://www.legionintel.com/blog/rag-systems-vs-lcw-performance-and-cost-trade-offs
- https://www.databricks.com/blog/long-context-rag-performance-llms
- https://arxiv.org/html/2411.03538v1
- https://arxiv.org/abs/2407.01370
- https://blog.dailydoseofds.com/p/will-long-context-llms-make-rag-obsolete
- https://arxiv.org/abs/2502.09977
- https://openreview.net/forum?id=CLF25dahgA
- https://github.com/Alibaba-NLP/LaRA
- https://www.databricks.com/blog/long-context-rag-capabilities-openai-o1-and-google-gemini
- https://www.llamaindex.ai/blog/towards-long-context-rag
- https://snorkel.ai/blog/long-context-models-in-the-enterprise-benchmarks-and-beyond/
- https://stackoverflow.blog/2024/04/02/are-long-context-windows-the-end-of-rag/
- https://zilliz.com/blog/will-retrieval-augmented-generation-RAG-be-killed-by-long-context-LLMs
- https://ai.google.dev/gemini-api/docs/long-context
- https://github.com/gkamradt/LLMTest_NeedleInAHaystack
- https://arize.com/blog-course/the-needle-in-a-haystack-test-evaluating-the-performance-of-llm-rag-systems/
- https://blog.langchain.com/multi-needle-in-a-haystack/
- https://kanerika.com/blogs/rag-vs-llm/
- https://dev.to/m_sea_bass/understanding-rag-and-long-context-llms-insights-from-the-self-route-hybrid-approach-2mfa
- https://www.getmaxim.ai/blog/llm-rag-compare/
- https://www.analyticsvidhya.com/blog/2024/10/evolution-of-agentic-rag/
- https://arxiv.org/abs/2508.14817
- https://arxiv.org/html/2506.03989v1
- https://arxiv.org/html/2503.00353v1
